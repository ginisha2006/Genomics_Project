{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d05b9cb8",
            "metadata": {},
            "source": [
                "# Genome Reconstruction from Sequenced Reads (Global Alignment: Needleman-Wunsch)\n",
                "\n",
                "This notebook demonstrates a simple pipeline for reconstructing a reference genome from a set of sequenced reads using **seeding, hashing, and global alignment (Needleman-Wunsch)**. The workflow includes:\n",
                "\n",
                "- Defining a reference genome and simulated reads\n",
                "- Efficient seeding and hashing to find candidate match regions\n",
                "- Global alignment using the Needleman-Wunsch algorithm\n",
                "- Consensus-based reconstruction of the reference genome\n",
                "\n",
                "This version uses **global alignment** (Needleman-Wunsch), which aligns each read to the reference segment end-to-end, penalizing gaps at the ends as well as in the middle."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "66ecee28",
            "metadata": {},
            "source": [
                "## 1. Inputs\n",
                "\n",
                "Define the reference genome and the set of sequenced reads. You can switch between different sets of reads to test the pipeline's robustness."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "017f732d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reference genome (example)\n",
                "reference_genome = \"AGTCGATGCTAGCTTACGGTACCGTAGGCTAGGATCGTACGCTAGGTAGCTAGCTAGCATGCTAGCTAGTTCGATCGTACGTAGCTTAGCTAGCATCGTAGCTAGCTAGGTACGATCGATCGTAGCATGCTAGCTAGGTAGCTAGCTTACGTACGTAGGCTAGCTAGCGTACGATCGTACGCTAGCTAGGCTAGCTAGCTAGCGTACGTAG\"\n",
                "\n",
                "# Example: reads exactly matching the reference genome\n",
                "sequenced_reads = [\n",
                "    \"AGTCGATGCTAGCTTACGGT\", \"GATGCTAGCTTACGGTACCG\", \"CTAGCTTACGGTACCGTAGG\",\n",
                "    \"TTACGGTACCGTAGGCTAGG\", \"TACCGTAGGCTAGGATCGTA\", \"TAGGCTAGGATCGTACGCTA\",\n",
                "    \"AGGATCGTACGCTAGGTAGC\", \"GTACGCTAGGTAGCTAGCTA\", \"TAGGTAGCTAGCTAGCATGC\",\n",
                "    \"GTAGCTAGCTAGCATGCTAG\", \"CTAGCTAGTTCGATCGTACG\", \"AGTTCGATCGTACGTAGCTT\",\n",
                "    \"CGATCGTACGTAGCTTAGCT\", \"GTACGTAGCTTAGCTAGCAT\", \"TAGCTTAGCTAGCATCGTAG\",\n",
                "    \"GCTAGCATCGTAGCTAGCTA\", \"ATCGTAGCTAGCTAGGTACG\", \"AGCTAGCTAGGTACGATCGA\",\n",
                "    \"CTAGGTACGATCGATCGTAG\", \"GTACGATCGATCGTAGCATG\", \"ATCGATCGTAGCATGCTAGC\",\n",
                "    \"CGTAGCATGCTAGCTAGGTA\", \"CATGCTAGCTAGGTAGCTAG\", \"GCTAGCTAGGTAGCTAGCTT\",\n",
                "    \"GTAGGTAGCTAGCTTACGTA\", \"TAGCTTACGTACGTAGGCTA\", \"TACGTACGTAGGCTAGCTAG\",\n",
                "    \"GTAGGCTAGCTAGCGTACGA\", \"CTAGCGTACGATCGTACGCT\", \"CGTACGATCGTACGCTAGCT\",\n",
                "    \"TCGATCGTACGCTAGCTAGG\", \"ACGCTAGCTAGGCTAGCTAG\", \"TAGGCTAGCTAGCTAGCGTA\",\n",
                "    \"AGCTAGCTAGCGTACGTAGT\", \"TAGCGTACGTAGTCCGATGG\", \"CGTACGTAGTCCGATGGCAA\",\n",
                "    \"AGTCCGATGGCAAGTCTTGA\"\n",
                "]\n",
                "\n",
                "# To test with noisy or unrelated reads, uncomment one of the following blocks:\n",
                "\n",
                "#Sequenced reads from a genome mostly similar to reference genome\n",
                "# sequenced_reads = [\n",
                "#     \"AGTCGATGGT\", \"GATGCTAACTGACGG\", \"CTAGCTGACCATACCGCAGG\",\n",
                "#     \"TTACGGTATCGTAGGATAGG\", \"TACCGTAGACGATCCTA\", \"TAGGCTTGGATCATCCGCTA\",\n",
                "#     \"AGGATCGGATGTTAGGTACC\", \"GTACGCTACTTGGTAGCATA\", \"GGGGGGGGGGGGGAGGGGGG\",\n",
                "#     \"GTAGCTTGATAGCATGTTAG\", \"TTTGTTTCTTCTTCTTGTTT\", \"AGTTCGACCATCTC\",\n",
                "#     \"AAAAAAAAAAAAAAAAAAAA\", \"ATTGCGGTACTGGCATTGGG\", \"TAGCTTAACATCGTGG\",\n",
                "#     \"ATGGCGATTGCGATGGCAAA\", \"ATCGTAGCTGGCTAACC\", \"AGCCATTGGCATGCCATTGA\",\n",
                "#     \"CTAGGTACGATCCGTAGTGG\", \"AAAAAAAAAAATAAAAAAAA\", \"ATCGATCGTACCCTAGC\",\n",
                "#     \"CGTAGCATGATAGCTTGGTA\", \"CATGCTTGCTAGGTAACTAG\", \"GCTAGCTAGGATGCTAGATT\",\n",
                "#     \"GGGGGGGGGGGGGAGGGGGG\", \"AGTAACGTACAAGTCA\", \"TACGTACGTAGCCTAGTTAG\",\n",
                "#     \"GTAGGCTAGATAGCGTTCGA\", \"CTAGCGTACCATCGTATGCT\", \"CGTACGATCGTGCACT\",\n",
                "#     \"TCGATCGTAGCCTAGCTTGG\", \"ACGCTAGCTTGGCTAGATAG\", \"TAGGCTAGCTTCCAGCGTCA\",\n",
                "#     \"AGCTAGCTAGCGTACGTGGT\", \"TAGCGTACGTAGTCCGGTGA\", \"GGGGGGGGGGGTGGGGGGGG\",\n",
                "#     \"GGGGGGGGGGGGGAGGGGGG\"\n",
                "# ]\n",
                "\n",
                "#Sequenced reads from a genome almostly entirely different from reference genome\n",
                "# sequenced_reads = [\n",
                "#     \"TTCAGGTCACATGGGTTTCA\", \"GGAATCCTACGTTCGGAAGT\", \"CTTTCAGGAGATCCATGTGC\",\n",
                "#     \"AACCTGGATGACCAGTTCAA\", \"GGTTCAAGGACCTTCTTGAC\", \"ACTGGTGGTACCTTGGAAGA\",\n",
                "#     \"CCTAGGTTCACGGATCTGGT\", \"TCACAGTTTGGGACTCCGTT\", \"GGATCAGTACCAGCTGTTCA\",\n",
                "#     \"CCGTTAGGTTTGAGGTCTTC\", \"AGTGGATTCAGGATGGTGTT\", \"TCTGGAGGTTCCATGTAGAG\",\n",
                "#     \"GGAACCTTGGAAGTCCATAC\", \"TAGGTCAGTGGTACCGTGAT\", \"CTTGATGGTGACCAGGATAC\",\n",
                "#     \"TGGAGTTCAGGTGTACCATG\", \"GAACCTTGACTGGCTTGTGC\", \"ATCCAGGAGTTCACGGTGAT\",\n",
                "#     \"TTGGCAGTACCGTGGGAACT\", \"GCATCTTACCGATGGCAGGT\", \"TACCTGGAGTTCAAGGCTGA\",\n",
                "#     \"AGGATCTTGGTACCAGTTTC\", \"GTTACCGGTCATGTAGGCAC\", \"TCAGGTTGGATCTGGTACAG\",\n",
                "#     \"GAGTCTTTCAGGACCGTCAA\", \"TTAGTCACGGTTAGCATCCA\", \"CTGGTGAGTCCGGATACCGT\",\n",
                "#     \"AACGTGGCTTCAGATCGGTT\", \"CGGTGACTTGAAGATGCCAG\", \"TTCAGCTAGGTACCTAGTCA\",\n",
                "#     \"ACGTGTCAGGTCTAGGATCC\", \"GAAGTACCGTTGTGGAGTCA\", \"TCTGGTTGAGATGCCATACC\",\n",
                "#     \"GTTGACCTTGTCAGTGGGAA\", \"ATCCGTTCAGGATCGTGACC\", \"CAGTGTTGGAACCTTGTCCA\"\n",
                "# ]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f01a9704",
            "metadata": {},
            "source": [
                "## 2. Utility Functions\n",
                "\n",
                "Includes hash functions for efficient seeding, scoring matrices, and the Needleman-Wunsch global alignment implementation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "70f6eed3",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from collections import Counter\n",
                "\n",
                "# DNA base to number mapping for hashing\n",
                "mapping = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
                "\n",
                "def custom_hash(seed, base=4):\n",
                "    \"\"\"Full hash calculation for a k-mer (seed)\"\"\"\n",
                "    h = 0\n",
                "    for char in seed:\n",
                "        h = h * base + mapping[char]\n",
                "    return h\n",
                "\n",
                "def rolling_hash(prev_hash, out_char, in_char, k, base=4):\n",
                "    \"\"\"Efficiently update hash when sliding window moves by one base\"\"\"\n",
                "    out_val = mapping[out_char]\n",
                "    in_val = mapping[in_char]\n",
                "    prev_hash -= out_val * (base ** (k - 1))\n",
                "    prev_hash = prev_hash * base + in_val\n",
                "    return prev_hash\n",
                "\n",
                "# Scoring and penalty values for alignment\n",
                "match_reward = 2\n",
                "mismatch_penalty = -1\n",
                "gap_penalty = -2  # Typically, gap penalty is more negative than mismatch\n",
                "\n",
                "# Base to index mapping for scoring matrix\n",
                "base_index = {'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
                "scoring_matrix = np.array([\n",
                "    [match_reward, mismatch_penalty, mismatch_penalty, mismatch_penalty],\n",
                "    [mismatch_penalty, match_reward, mismatch_penalty, mismatch_penalty],\n",
                "    [mismatch_penalty, mismatch_penalty, match_reward, mismatch_penalty],\n",
                "    [mismatch_penalty, mismatch_penalty, mismatch_penalty, match_reward]\n",
                "])\n",
                "\n",
                "def get_score(b1, b2):\n",
                "    \"\"\"Get score for a pair of bases from the scoring matrix\"\"\"\n",
                "    return scoring_matrix[base_index[b1], base_index[b2]]\n",
                "\n",
                "def needleman_wunsch(sequence_1, sequence_2):\n",
                "    \"\"\"Space Optimsied Global alignment using Needleman-Wunsch algorithm with traceback support.\"\"\"\n",
                "    m, n = len(sequence_1), len(sequence_2)\n",
                "    prev_row = np.zeros(len(sequence_2)+1)\n",
                "    curr_row = np.zeros(len(sequence_2)+1)\n",
                "    max_score = 0\n",
                "    max_pos = (0, 0)\n",
                "    traceback_matrix = np.zeros((len(sequence_1)+1, len(sequence_2)+1), dtype=int)\n",
                "\n",
                "    # Initialize first row\n",
                "    for j in range(n + 1):\n",
                "        prev_row[j] = j * gap_penalty\n",
                "\n",
                "    for i in range(1, m + 1):\n",
                "        curr_row[0] = i * gap_penalty\n",
                "        for j in range(1, n + 1):\n",
                "            diag = prev_row[j - 1] + get_score(sequence_1[i-1], sequence_2[j-1])\n",
                "            up = prev_row[j] + gap_penalty\n",
                "            left = curr_row[j - 1] + gap_penalty\n",
                "            curr_row[j] = max(diag, up, left)\n",
                "\n",
                "            # Traceback matrix: 1 = diag, 2 = up, 3 = left\n",
                "            if curr_row[j] == diag:\n",
                "                traceback_matrix[i][j] = 1\n",
                "            elif curr_row[j] == up:\n",
                "                traceback_matrix[i][j] = 2\n",
                "            else:\n",
                "                traceback_matrix[i][j] = 3\n",
                "\n",
                "        prev_row, curr_row = curr_row, np.zeros(n + 1)\n",
                "\n",
                "    # Traceback\n",
                "    aligned1, aligned2 = \"\", \"\"\n",
                "    i, j = m, n\n",
                "    while i > 0 or j > 0:\n",
                "        if i > 0 and j > 0 and traceback_matrix[i][j] == 1:\n",
                "            aligned_1 = sequence_1[i-1] + aligned_1\n",
                "            aligned_2 = sequence_2[j-1] + aligned_2\n",
                "            i -= 1\n",
                "            j -= 1\n",
                "        elif i > 0 and (j == 0 or traceback_matrix[i][j] == 2):\n",
                "            aligned_1 = sequence_1[i-1] + aligned_1\n",
                "            aligned_2 = '-' + aligned_2\n",
                "            i -= 1\n",
                "        else:\n",
                "            aligned_1 = '-' + aligned_1\n",
                "            aligned_2 = sequence_2[j-1] + aligned_2\n",
                "            j -= 1\n",
                "\n",
                "    return aligned1, aligned2"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "complexity-utility",
            "metadata": {},
            "source": [
                "### Rolling Hash and Utility Function Complexity\n",
                "\n",
                "**Rolling Hash Table Construction:**\n",
                "- **Time Complexity:** O(N), where N is the length of the reference genome. Each k-mer hash is computed in O(1) time after the first, thanks to the rolling hash.\n",
                "- **Space Complexity:** O(N), for storing all k-mer hashes and their positions.\n",
                "\n",
                "**Custom Hash:**\n",
                "- **Time Complexity:** O(k), where k is the seed length (very small, typically 3-10).\n",
                "- **Space Complexity:** O(1).\n",
                "\n",
                "**Smith-Waterman Local Alignment:**\n",
                "- **Time Complexity:** O(M×K) per alignment, where M is the read length and K is the reference segment length (usually ≈ M).\n",
                "- **Space Complexity:** \n",
                "                        O(M+K) per alignment without traceback (space-optimized variant).\n",
                "                        O(M×K) with traceback (as implemented)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3e57351d",
            "metadata": {},
            "source": [
                "## 3. Seeding: Find Matching Regions\n",
                "\n",
                "Use k-mer seeding and hashing to quickly find candidate regions in the reference genome for each read. The reference genome is indexed using rolling hash values for all k-mers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "843dc08a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_matching_regions(reference_genome, sequenced_reads, seed_length=3):\n",
                "    \"\"\"Seeding using first k-mer of each read to find candidate match locations in the reference genome.\"\"\"\n",
                "    seed_table = {}\n",
                "    ref_hash = custom_hash(reference_genome[:seed_length])\n",
                "    seed_table.setdefault(ref_hash, []).append(0)\n",
                "    for i in range(1, len(reference_genome) - seed_length + 1):\n",
                "        ref_hash = rolling_hash(ref_hash, reference_genome[i - 1], reference_genome[i + seed_length - 1], seed_length)\n",
                "        seed_table.setdefault(ref_hash, []).append(i)\n",
                "    matching_regions = {}\n",
                "    for read in sequenced_reads:\n",
                "        read_seed = read[:seed_length]\n",
                "        h = custom_hash(read_seed)\n",
                "        matching_regions[read] = seed_table.get(h, [])\n",
                "    return matching_regions"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "complexity-seeding",
            "metadata": {},
            "source": [
                "### Seeding Complexity\n",
                "\n",
                "- **Rolling Hash Table Construction:**\n",
                "  - **Time Complexity:** O(N), where N is the reference genome length.\n",
                "  - **Space Complexity:** O(N), for storing all k-mer hashes and their positions.\n",
                "\n",
                "- **Read Seeding Lookup:**\n",
                "  - **Time Complexity:** O(1) per read for hash lookup (plus O(1) for hash computation).\n",
                "  - **Space Complexity:** O(R), where R is the number of reads (for storing match lists)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8cfff495",
            "metadata": {},
            "source": [
                "## 4. Global Alignment and Read Placement\n",
                "\n",
                "For each read, use Needleman-Wunsch to align it to all candidate regions, and record the best alignment and its position."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f76c1df3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Find probable match locations for all the reads\n",
                "matching_regions = find_matching_regions(reference_genome, sequenced_reads)\n",
                "\n",
                "# Step 2: Initialize mapping for aligned bases to each reference genome position\n",
                "ref_alignments = {i: [] for i in range(len(reference_genome))}\n",
                "\n",
                "# Step 3: For each read, align to candidate regions and record best alignment\n",
                "for read, positions in matching_regions.items():\n",
                "    if not positions:\n",
                "        print(f\"Read: {read} → Most probable region: None\")\n",
                "        continue\n",
                "    best_score = -float('inf')\n",
                "    best_alignment = (\"\", \"\")\n",
                "    best_position = -1\n",
                "    for pos in positions:\n",
                "        ref_segment = reference_genome[pos:pos + len(read)]\n",
                "        aligned_read, aligned_ref = needleman_wunsch(read, ref_segment)\n",
                "        # Calculate alignment score\n",
                "        score = 0\n",
                "        for r, g in zip(aligned_read, aligned_ref):\n",
                "            if r == '-' or g == '-':\n",
                "                score += gap_penalty\n",
                "            else:\n",
                "                score += get_score(r, g)\n",
                "        if score > best_score:\n",
                "            best_score = score\n",
                "            best_alignment = (aligned_read, aligned_ref)\n",
                "            best_position = pos\n",
                "    # Print alignment summary\n",
                "    if best_position == -1:\n",
                "        print(f\"Read: {read} → Most probable region: None\")\n",
                "    else:\n",
                "        print(f\"\\nRead: {read}\")\n",
                "        print(f\"→ Most probable region (starting at {best_position}): {reference_genome[best_position:best_position+len(read)]}\")\n",
                "        print(\"→ Global Alignment (Needleman-Wunsch):\")\n",
                "        print(f\"   Read : {best_alignment[0]}\")\n",
                "        print(f\"   Ref  : {best_alignment[1]}\")\n",
                "        # Record aligned bases for consensus\n",
                "        ref_pos = best_position\n",
                "        ref_index = 0\n",
                "        for r_base, g_base in zip(*best_alignment):\n",
                "            if g_base != '-':\n",
                "                ref_alignments[ref_pos + ref_index].append(r_base)\n",
                "                ref_index += 1"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "complexity-alignment",
            "metadata": {},
            "source": [
                "### Alignment Step Complexity\n",
                "\n",
                "For each read, we align it to all candidate regions using Smith-Waterman:\n",
                "\n",
                "- **Time Complexity:** O(R × C × M × K)\n",
                "  - R = number of reads\n",
                "  - C = average number of candidate regions per read\n",
                "  - M = read length\n",
                "  - K = reference segment length (usually ≈ M)\n",
                "- **Space Complexity:** O(M × K) if traceback is used to reconstruct aligned sequences (which has been implemented).\n",
                "\n",
                "O(M + K) only if traceback is avoided and only the alignment score is required (not the aligned sequences).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8d03f5b0",
            "metadata": {},
            "source": [
                "## 5. Consensus Genome Reconstruction\n",
                "\n",
                "For each position in the reference genome, select the most common aligned base from all reads to reconstruct the genome."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0aa03463",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 4: Reconstruct the reference genome from consensus\n",
                "reconstructed_reference = ''\n",
                "for i in range(len(reference_genome)):\n",
                "    if ref_alignments[i]:\n",
                "        base_counts = Counter(ref_alignments[i])\n",
                "        most_common_base = base_counts.most_common(1)[0][0]\n",
                "        reconstructed_reference += most_common_base\n",
                "    else:\n",
                "        reconstructed_reference += '-'\n",
                "print(\"\\nReconstructed Reference Genome:\", reconstructed_reference)\n",
                "print(\"Reference Genome              :\", reference_genome)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "complexity-consensus",
            "metadata": {},
            "source": [
                "### Consensus Step Complexity\n",
                "\n",
                "- **Time Complexity:** O(N × D)\n",
                "  - N = reference genome length\n",
                "  - D = average depth of aligned reads per position\n",
                "- **Space Complexity:** O(N × D) for storing all aligned bases\n",
                "\n",
                "The consensus is built by taking the most common base at each position."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
